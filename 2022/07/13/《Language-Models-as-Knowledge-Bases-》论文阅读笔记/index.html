

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="John Doe">
  <meta name="keywords" content="">
  
    <meta name="description" content="paper：https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1909.01066 code：https:&#x2F;&#x2F;github.com&#x2F;facebookresearch&#x2F;LAMA 来源：EMNLP 2019 作者单位：Facebook AI 研究院，伦敦大学学院  这项研究所揭示的重要结论：  BERT-large 模型捕获了（准确的）关系知识，该知识与使用现成的关系提取器和基于oracle 的实体链接器从">
<meta property="og:type" content="article">
<meta property="og:title" content="《Language Models as Knowledge Bases?》论文阅读笔记">
<meta property="og:url" content="http://example.com/2022/07/13/%E3%80%8ALanguage-Models-as-Knowledge-Bases-%E3%80%8B%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="paper：https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1909.01066 code：https:&#x2F;&#x2F;github.com&#x2F;facebookresearch&#x2F;LAMA 来源：EMNLP 2019 作者单位：Facebook AI 研究院，伦敦大学学院  这项研究所揭示的重要结论：  BERT-large 模型捕获了（准确的）关系知识，该知识与使用现成的关系提取器和基于oracle 的实体链接器从">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://pic2.zhimg.com/v2-6cfa5024e7ca097a7b43ee6e3008a4a0_1440w.jpg?source=172ae18b">
<meta property="og:image" content="https://img-blog.csdnimg.cn/ca85281766ab45e080354686663bc17b.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/fbc3c87c337c4def9bae9d02ce8ff6d5.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/b868f60f4a754574b67433c5c68c2ee0.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/e859bf750ecf43c19efe779f363807fd.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/8464bf7bb26a4bb7bc1bc6c9146785ca.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAQlFXXw==,size_20,color_FFFFFF,t_70,g_se,x_16">
<meta property="og:image" content="https://img-blog.csdnimg.cn/9f448e6b181144b09d1ef5a5b7bd78b1.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAQlFXXw==,size_20,color_FFFFFF,t_70,g_se,x_16">
<meta property="og:image" content="https://img-blog.csdnimg.cn/772c90faf7784e5f87fd45c285d9a8c2.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAQlFXXw==,size_20,color_FFFFFF,t_70,g_se,x_16">
<meta property="article:published_time" content="2022-07-13T04:02:21.000Z">
<meta property="article:modified_time" content="2022-07-23T10:48:00.846Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="Paper Reading">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://pic2.zhimg.com/v2-6cfa5024e7ca097a7b43ee6e3008a4a0_1440w.jpg?source=172ae18b">
  
  
  
  <title>《Language Models as Knowledge Bases?》论文阅读笔记 - Hexo</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.2","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 6.2.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>YFHuang&#39;s blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/test.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="《Language Models as Knowledge Bases?》论文阅读笔记"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2022-07-13 12:02" pubdate>
          2022年7月13日 中午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          5.9k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          49 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">《Language Models as Knowledge Bases?》论文阅读笔记</h1>
            
            
              <div class="markdown-body">
                
                <p>paper：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1909.01066">https://arxiv.org/abs/1909.01066</a></p>
<p>code：<a target="_blank" rel="noopener" href="https://github.com/facebookresearch/LAMA">https://github.com/facebookresearch/LAMA</a></p>
<p>来源：EMNLP 2019</p>
<p>作者单位：Facebook AI 研究院，伦敦大学学院</p>
<p><img src="https://pic2.zhimg.com/v2-6cfa5024e7ca097a7b43ee6e3008a4a0_1440w.jpg?source=172ae18b" srcset="/img/loading.gif" lazyload alt="【EMNLP 2019】Language Models as Knowledge Bases?"></p>
<p><strong>这项研究所揭示的重要结论</strong>：</p>
<ul>
<li>BERT-large 模型捕获了（准确的）关系知识，该知识与使用现成的关系提取器和基于oracle 的实体链接器从已知表示相关知识的语料库中提取的知识库相当。</li>
<li>BERT-large 在开放域 QA 中取得了显着的结果，与使用任务特定的监督关系提取系统构建的知识库取得的 63.5% precision@10 相比，它取得了 57.1 % 的效果。</li>
<li>BERT-large 在恢复事实和常识性知识方面始终优于其他语言模型。</li>
<li>事实知识可以从预训练语言模型中意外地很好地恢复，但是，对于某些关系（特别是 N 对M 关系）的性能非常差。</li>
</ul>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>语言模型用于预测句子中的下一个单词，或者给定句子预测其中任何位置的被掩盖的单词。预训练模型需要存储大量的对下游任务有用的语言学知识。通常通过以原始模型产生的潜在上下文表示为条件，或通过使用原始模型权重来初始化特定于任务的模型，然后进一步进行微调，来访问此知识。此类知识转移对于当前在各种任务上的最新成果至关重要。</p>
<p>与此对比，知识库是通过使用查询来访问带注释的有严格标准关系的数据的有效方案。 但是，在实践中，我们经常需要<strong>从文本或其他方式中提取关系数据以填充这些知识库</strong>。 这需要复杂的 NLP 流水线，包括实体提取，共指解析，实体链接和关系提取，这些组件通常需要监督数据和固定模式。 而且，错误很容易在整个流水线中传播和累积。相反，我们可以尝试通过要求以关系数据的形式查询神经语言模型，例如“ Dante出生于[Mask]”。在这种情况下，<strong>语言模型具有各种吸引人的属性：它们不需要架构工程，不需要人工注释，并且支持一组开放的查询</strong>。</p>
<p><img src="https://img-blog.csdnimg.cn/ca85281766ab45e080354686663bc17b.png" srcset="/img/loading.gif" lazyload alt="在这里插入图片描述"></p>
<p>​                                                在知识库和语言模型中查询事实类知识</p>
<p>鉴于语言模型的上述特性可以作为关系知识的潜在表示形式，作者表示对预先训练的现成语言模型（例如 ELMo 和 BERT）中已经存在的关系知识感兴趣。 他们存储多少关系知识？ 对于不同类型的知识（例如有关实体的事实、常识和一般性问答），这有何不同？ 与从文本中自动提取的符号知识库相比，无需微调的性能如何？ 除了收集对这些模型的更好的一般理解之外，我们认为这些问题的答案可以帮助我们设计更好的无监督知识表示，这些知识表示可以将事实知识和常识性知识可靠地转移到下游任务，例如常识（视觉）问题解答或增强学习。</p>
<p>为了解答上述问题，该文介绍了 LAMA（LAnguage Model Analysis），<strong>包含一系列知识源，每个知识源包含一组事实。作者定义，一个语言模型知道一个事实（主体，关系，客体）当它在完形填空任务中能成功预测被掩盖的客体时。</strong></p>
<p>作者测试各种类型的知识：存储在 Wikidata 中的实体之间的关系，ConceptNet 概念之间的常识关系以及回答 SQuAD 中自然语言问题所必需的知识。 在后一种情况下，作者手动映射SQuAD 问题的子集以结束句子。</p>
<h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><p>在背景介绍了几种语言模型：</p>
<p><img src="https://img-blog.csdnimg.cn/fbc3c87c337c4def9bae9d02ce8ff6d5.png" srcset="/img/loading.gif" lazyload alt="在这里插入图片描述"></p>
<h3 id="1-Unidirectional-language-models"><a href="#1-Unidirectional-language-models" class="headerlink" title="1.Unidirectional language models"></a>1.Unidirectional language models</h3><p>给定一个输入序列 w &#x3D; [w1, w2, … , wN] ，单向语言模型会将整个输入序列按下面的方式进行分解p (w) :</p>
<p><img src="https://img-blog.csdnimg.cn/b868f60f4a754574b67433c5c68c2ee0.png" srcset="/img/loading.gif" lazyload alt="在这里插入图片描述"></p>
<p>一个比较通用的方法是通过神经网络来估计概率<br><img src="https://img-blog.csdnimg.cn/e859bf750ecf43c19efe779f363807fd.png" srcset="/img/loading.gif" lazyload alt="在这里插入图片描述"><br>其中，ht ∈ R^k 是神经网络在位置 t 的输出向量，W∈R^(∣V∣×k)是一个可学习参数，用于将ht映射为词表 V 中每个词的非标准化分数。获得 ht 的神经网络结构可能有所不同，比如有多层感知器，卷积层，循环神经网络以及自注意力机制。</p>
<p>典型的单向语言模型为<strong>fairseq-fconv</strong>和<strong>Transformer-XL。</strong>。</p>
<h3 id="2-Bidirectional-language-models"><a href="#2-Bidirectional-language-models" class="headerlink" title="2.Bidirectional language models"></a>2.Bidirectional language models</h3><p>单向语言模型通过上文词语来预测下一个词。但是，一个词的含义是同时由上下文决定的。因此，给定输入序列 w &#x3D; [w1, w2, … , wN]和一个位置 1 ≤ i ≤ N，那么双向语言模型期望估计概率p (wi∣w1, … , wi−1, wi+1, … , wN) 会用这个词的上下文。</p>
<p>典型的单向语言模型为<strong>ELMO</strong>和<strong>BERT。</strong></p>
<h2 id="LAMA-探针"><a href="#LAMA-探针" class="headerlink" title="LAMA 探针"></a>LAMA 探针</h2><p>论文引入的LAMA探针可以用来测试语言模型中的事实和常识知识。该探针本质上提供了一组由<strong>事实</strong>组成的知识源。这里的事实是指subject-relation-object三元组或者问答对。每个事实都会被转换为“完型填空”形式的陈述句(prompt)，然后用来从语言模型中查询目标token。举例来说，给定一个事实(dante, born-in, florence)，如果要查询是否包含该知识，可以将其转换为陈述句Dante was born-in ___。</p>
<p> 在评估效果时，会根据真实token在候选词表中的位置进行评估，排名越靠前，则认为模型包含越多的知识。</p>
<h3 id="1-知识源"><a href="#1-知识源" class="headerlink" title="1. 知识源"></a>1. 知识源</h3><p>为了评估分析在前面介绍语言模型的时候不同的语言模型，在这里作者介绍包含了很多源的事实和常识知识。</p>
<h4 id="1-1-Google-RE"><a href="#1-1-Google-RE" class="headerlink" title="1.1 Google-RE"></a>1.1 Google-RE</h4><p> 语料Google-RE是从wikipedia中人工抽取的、包含60K事实的知识源，其覆盖了5种关系。但LAMA探针仅考虑其中的三种：place of birth、date of birth和place of death。排除另外两种的原因是，在评估中不支持多token对象。对于三元组事实中的每个关系，都会定义一个模板，例如：”[S] was born in [O]“为关系place of birth的模板。</p>
<h4 id="1-2-T-REx"><a href="#1-2-T-REx" class="headerlink" title="1.2 T-REx"></a>1.2 T-REx</h4><p> 知识源T-REx是wikipedia三元组的子集，其要比Google-RE大得多，且拥有更加广泛的关系集合。LAMA中考虑了41个wikipedia中的关系，并且每种关系采样1000个事实。同Google-RE数据集一样，我们人工为每个关系定义了模板(prompt)。</p>
<h4 id="1-3-ConceptNet"><a href="#1-3-ConceptNet" class="headerlink" title="1.3 ConceptNet"></a>1.3 ConceptNet</h4><p> ConceptNet是一个多语言知识库，该知识库是从Open Mind Common Sense(OMCS)中的句子构造出来的。LAMA中仅考虑ConceptNet中英语部分的事实，其中有16种关系具有单个token的ojbect。对于任意ConceptNet三元组，可以从OMCS中找到同时包含subject和object的句子。对该句子中的object进行mask，从而构成一个prompt。若三元组对应多个句子，则随机挑选一个。</p>
<h4 id="1-4-SQuAD"><a href="#1-4-SQuAD" class="headerlink" title="1.4 SQuAD"></a>1.4 SQuAD</h4><p> SQuAD是一个常见的问答数据集，LAMA从SQuAD的开发集中挑选了305个具有单token答案且上下文不敏感的问题。人工从这些问题中创建完型填空风格的问题。例如，将”Who developed the theory of relativity?“重写为”The theory of relativity was developed by ___”。</p>
<h3 id="2-模型"><a href="#2-模型" class="headerlink" title="2. 模型"></a>2. 模型</h3><p> 论文中测试的语言模型有：fairseq-fconv(Fs)、Transformer-XL large(Txl)、ELMo original(Eb)、ELMo 5.5B(E5B)、BERT-base(Bb)和BERT-large(Bl)。</p>
<p> 模型的目标是预测特定位置t处的token。对于单向语言模型，使用t-1处网络生成的向量      （ <strong>h</strong>t−1）进行预测。对于ELMo，则会使用前向的（ <strong>h</strong>t−1）和后向的（ <strong>h</strong>t+1）。对于BERT，则遮盖t处的token，然后将（ <strong>h</strong>t）输入softmax层。为了公正的比较，生成一个所有模型词表的交集，然后在该交集词表上预测token。</p>
<h3 id="3-基线"><a href="#3-基线" class="headerlink" title="3. 基线"></a>3. 基线</h3><p> 为了比较语言模型与传统系统，论文考虑了下面的baseline。</p>
<h4 id="3-1-Freq"><a href="#3-1-Freq" class="headerlink" title="3.1 Freq"></a>3.1 Freq</h4><p> 给定一个subject和relation关系对，该baseline会基于<strong>测试集</strong>中该关系对中出现的所有object的频率进行单词排序。该baseline是那些总是预测相同object的模型的上边界。</p>
<h4 id="3-2-RE"><a href="#3-2-RE" class="headerlink" title="3.2 RE"></a>3.2 RE</h4><p> 对于基于关系的知识源，使用一个预训练好的关系抽取模型RE，该模型在Wikidata上进行训练。该模型是基于LSTM和注意力机制的编码器，用于从句子中抽取三元组。RE对包含事实的句子进行三元组抽取，并构建知识图谱。在测试时，在图谱上查询指定的subject，然后基于RE返回的置信分数来排序object。</p>
<h4 id="3-3-DrQA"><a href="#3-3-DrQA" class="headerlink" title="3.3 DrQA"></a>3.3 DrQA</h4><p> DrQA是一个开放域问答系统，其使用两阶段的pipeline来回答自然语言问题。首先，使用TF-IDF从大量文档中检索出相关的文章，然后在检索出的topK的文章中，使用神经阅读理解模型来抽取答案。这里会显著DrQA只预测单个token，从而可以与语言模型进行比较。</p>
<h3 id="4-评估指标"><a href="#4-评估指标" class="headerlink" title="4. 评估指标"></a>4. 评估指标</h3><p> 使用基于rank的评估指标。</p>
<h3 id="5-注意事项"><a href="#5-注意事项" class="headerlink" title="5. 注意事项"></a>5. 注意事项</h3><h4 id="5-1-人工定义模板"><a href="#5-1-人工定义模板" class="headerlink" title="5.1 人工定义模板"></a>5.1 人工定义模板</h4><p> 对于每种关系，人工定义一个模板来查询关系种的object。显然，模板的选择会对预测结果产生影响。因此，LAMA探针任务可以看做是衡量语言模型中包含知识的下边界。此外，传统知识库只能通过一种方式来查询关系知识，例如查询关系<strong>works-For</strong>时，如果用户使用 <strong>is-working-for</strong>，那么准确率就为0。</p>
<h4 id="5-2-单个token"><a href="#5-2-单个token" class="headerlink" title="5.2 单个token"></a>5.2 单个token</h4><p> 在预测任务中仅考虑单个token。限制单个token的原因是，多token解码会引入额外的可调参数，这会导致不好衡量模型中的知识量。此外，准确确定多token仍然是一个有挑战的问题，特别是对于双向语言模型。</p>
<h4 id="5-3-Object槽"><a href="#5-3-Object槽" class="headerlink" title="5.3 Object槽"></a>5.3 Object槽</h4><p> 在预测任务中仅对三元组中的object进行预测，因为通过反向关系也可以预测subject。没有查询relation slot的原因有二。首先，关系通常会跨越多个token，但这目前还是挑战。其次，即使能够预测多token的relation，但关系可以由不同的词表达，这会对衡量精度带来问题。</p>
<h4 id="5-4-词表交集"><a href="#5-4-词表交集" class="headerlink" title="5.4 词表交集"></a>5.4 词表交集</h4><p> 待比较的模型是在不同的词表上进行训练的。例如，ELMo有800K的词表，BERT则仅使用30K的词表。显然，词表大小会影响LAMA探针中不同模型的表现。词表越大，那么就越难从大量token中预测出真正的目标。因此，LAMA中仅考虑一个大小写敏感的21K词表，其是所有待比较模型词表的交集。</p>
<h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><p><img src="https://img-blog.csdnimg.cn/8464bf7bb26a4bb7bc1bc6c9146785ca.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAQlFXXw==,size_20,color_FFFFFF,t_70,g_se,x_16" srcset="/img/loading.gif" lazyload alt="在这里插入图片描述"></p>
<p> 上表中汇总了主要的结果，显示了不同模型在不同语料上的top1平均准确率。下面分别讨论不同语料上的结果。</p>
<h4 id="6-1-Google-RE"><a href="#6-1-Google-RE" class="headerlink" title="6.1 Google-RE"></a>6.1 Google-RE</h4><p> BERT的base版和large版明显优于其他模型。在整体准确率上，相较于基于知识库的方法有2.2至2.9个准确率的提升。BERT-large的效果虽然很好，但不意味着其是以正确的方式得到的答案。因为，Google-RE中的句子很可能是BERT的训练语料，BERT-large可能并没有理解这些结果，只是通过共现模式学习到了subject和object的关系。(什么是真正的理解，人是理解了关系还是记住了更多的共现？)</p>
<h4 id="6-2-T-REx"><a href="#6-2-T-REx" class="headerlink" title="6.2 T-REx"></a>6.2 T-REx</h4><p> Google-RE中仅包含了较少的事实和仅有的3种关系，因此继续在更大的T-REx上进行实验。但是，实验结果与Google-RE一致。所以，BERT在检索事实知识方面的性能接近于现有的关系抽取系统和自动构建的知识库系统。按关系分类来看，BERT在 1-to-1 关系上的表现最好，在 N-to-M 的关系上表现最差。</p>
<p> 此外，下游模型可以利用语言模型输出的向量表示来学习，正确答案即使不排在第1，也会排的足够靠前。下图展示了所有模型的P@k曲线。对于BERT来说，正确的object被排在top10的有60%，排在top100的有80%。</p>
<p><img src="https://img-blog.csdnimg.cn/9f448e6b181144b09d1ef5a5b7bd78b1.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAQlFXXw==,size_20,color_FFFFFF,t_70,g_se,x_16" srcset="/img/loading.gif" lazyload alt="在这里插入图片描述"></p>
<p> 此外，BERT-large即使预测不对object，但也能预测出object的正确类型。(这个性质有益于使用prompt预测实体的类型)</p>
<p> 为了研究预训练语言模型对同一个事实的不同询问方式的变化(prompt的模板)。论文分析了每个关系中至多100个事实，并从T-REx中随机挑选出10个对齐的句子。每个句子中，遮盖掉object并使用模型进行预测。这可以测试一些语言模型从训练数据中记忆和召回的能力，因为这些模型已经在Wikipedia上训练过。下图展示了每个事实在10个不同查询上排序的平均分布。BERT和ELMo 5.5B的变化程度最低，正确的object接近平均的顶部。令人惊讶的是，ELMo original的表现也与BERT相差不大，但其并没有在训练时见过Wikipedia数据。Fairseq-fconv和Transformer-XL的变化程度高，因为其在训练时没有见过很多的Wikipedia数据。</p>
<p><img src="https://img-blog.csdnimg.cn/772c90faf7784e5f87fd45c285d9a8c2.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAQlFXXw==,size_20,color_FFFFFF,t_70,g_se,x_16" srcset="/img/loading.gif" lazyload alt="在这里插入图片描述"></p>
<h4 id="6-3-ConceptNet"><a href="#6-3-ConceptNet" class="headerlink" title="6.3 ConceptNet"></a>6.3 ConceptNet</h4><p> 在ConceptNet上检索事实的结果与Google-RE、T-REx一致，BERT-large的模型表现的最好。</p>
<h4 id="6-4-SQuAD"><a href="#6-4-SQuAD" class="headerlink" title="6.4 SQuAD"></a>6.4 SQuAD</h4><p> 在开发域问答上BERT-large和DrQA还是有一定的差距(也就是有改进的空间)。但是，预训练语言模型是完全无监督的，且没有专门的信息检索系统。此外，还比较了DrQA和BERT-large的P@10，发现差距十分的小。BERT-large为57.1，而DrQA为63.5。(如果top1更准的话，BERT可以直接作为问答系统)</p>
<h2 id="讨论与结论"><a href="#讨论与结论" class="headerlink" title="讨论与结论"></a>讨论与结论</h2><p>作者通过事实和常识问题的系统性分析，发现 BERT-large 能够比其竞争对手更好地回忆起这些知识，并且在非神经和有监督的替代品方面具有明显的竞争力。 请注意，作者没有比较相应的架构和目标在给定的正文中捕获知识的能力，而是将重点放在现有的预训练模型权重中所存在的知识上，这些模型已被许多研究人员用作研究的起点。了解我们常用的模型和学习算法正在捕获哪些数据方面是至关重要的研究领域，并且本文对许多专注于所学习数据的语言特性的研究进行了补充。</p>
<p>作者发现从与标准性能相当的文本中提取知识库，直接使用预训练的 BERT-large 并非难事。尽管为关系提取基线仅提供了可能表达目标事实的数据，从而减少了假阴性的可能性，以及使用了慷慨的实体链接预言。作者怀疑 BERT 可能由于其处理的数据量较大而具有优势，因此将 Wikitext-103 作为附加数据添加到关系提取系统，并且观察到性能没有明显变化。这表明尽管可能无法通过更多数据来提高关系提取性能，但将来在不断增长的语料库上训练的语言模型可能会成为将来从文本中提取的传统知识库的可行替代方案。</p>
<p>除了使用 LAMA 探针测试未来的预训练语言模型外，我们还希望量化关于各种自然语言模板的回忆事实知识的方差。此外，评估多记号答案仍然是作者评估设置面临的开放挑战。</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/Paper-Reading/">#Paper Reading</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>《Language Models as Knowledge Bases?》论文阅读笔记</div>
      <div>http://example.com/2022/07/13/《Language-Models-as-Knowledge-Bases-》论文阅读笔记/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>John Doe</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2022年7月13日</div>
        </div>
      
      
      <div class="license-meta-item">
        <div>许可协议</div>
        <div>
          
            
            
              <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
              <span class="hint--top hint--rounded" aria-label="BY - 署名">
                <i class="iconfont icon-by"></i>
              </span>
              </a>
            
          
        </div>
      </div>
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2022/07/13/%E8%8B%B1%E6%96%87%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C%E8%A1%A8%E8%BE%BE%E7%A7%AF%E7%B4%AF/" title="英文论文写作表达积累">
                        <span class="hidden-mobile">英文论文写作表达积累</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      headingSelector : CONFIG.toc.headingSelector || 'h1,h2,h3,h4,h5,h6',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      collapseDepth   : CONFIG.toc.collapseDepth || 0,
      scrollSmooth    : true,
      headingsOffset  : -boardTop
    });
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
