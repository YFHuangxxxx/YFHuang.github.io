

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="John Doe">
  <meta name="keywords" content="">
  
    <meta name="description" content="开一篇文用于记录日常读paper时好的英文表达。 Sentence The target task can be performed conditioning the LLM with task-specific prompts, a small portion of parameters, or features. 在…有着…的条件下  The optimization can be highl">
<meta property="og:type" content="article">
<meta property="og:title" content="英文论文写作表达积累">
<meta property="og:url" content="http://example.com/2022/07/13/%E8%8B%B1%E6%96%87%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C%E8%A1%A8%E8%BE%BE%E7%A7%AF%E7%B4%AF/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="开一篇文用于记录日常读paper时好的英文表达。 Sentence The target task can be performed conditioning the LLM with task-specific prompts, a small portion of parameters, or features. 在…有着…的条件下  The optimization can be highl">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2022-07-13T03:20:26.000Z">
<meta property="article:modified_time" content="2022-07-27T11:15:56.642Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="Paper Writing">
<meta name="twitter:card" content="summary_large_image">
  
  
  
  <title>英文论文写作表达积累 - Hexo</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.2","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 6.2.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>YFHuang&#39;s blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/test.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="英文论文写作表达积累"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2022-07-13 11:20" pubdate>
          2022年7月13日 上午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          6.9k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          58 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">英文论文写作表达积累</h1>
            
            
              <div class="markdown-body">
                
                <p>开一篇文用于记录日常读paper时好的英文表达。</p>
<h2 id="Sentence"><a href="#Sentence" class="headerlink" title="Sentence"></a>Sentence</h2><ol>
<li><p>The target task can be performed <strong>conditioning</strong> the LLM <strong>with</strong> task-specific prompts, a small portion of parameters, or features. 在…有着…的条件下</p>
</li>
<li><p>The optimization can be highly efficient since it does not require backpropagation, <strong>where</strong> （修饰backpropagation） the computation complexity <strong>is proportional</strong> <strong>to</strong> the model size and therefore can be expensive or even infeasible for LLMs.  与…成正比</p>
</li>
<li><p>It has been demonstrated that LLMs can <strong>achieve competitive performance</strong> <strong>on a broad range of tasks</strong> with limited or even zero labeled data. </p>
</li>
<li><p>Most works in LMaaS also <strong>focus on few-shot or zero-shot settings.</strong></p>
</li>
<li><p>…lead to a surge of improvements for downstream NLP tasks 导致推进了下游NLP任务的快速发展</p>
</li>
<li><p><strong>Whilst</strong> learning linguistic knowledge,  在…的同时</p>
</li>
<li><p>We present an in-depth analysis of the ….  in a wide range of stste-of-the-art pretrained language models 我们做了一个更深层次的分析</p>
</li>
<li><p>BERT <strong>does remarkably well</strong> on … against …</p>
</li>
<li><p>certain types of factual knowledge <strong>are learned much more readily</strong> than…</p>
</li>
<li><p>the <strong>surprisingly strong ability</strong> of … demonstrates their potential as …</p>
</li>
<li><p><strong>they are optimised to</strong> either predict the next word in a sequence or some masked word anywhere in a given sequence.</p>
</li>
<li><p>…is <strong>crucial</strong> for current state-of-art results</p>
</li>
<li><p>Moreover, errors can easily <strong>propagate and accumulate</strong> throughout the pipeline</p>
</li>
<li><p>language models <strong>come with various attractive properties</strong></p>
</li>
<li><p>beyond gathering a better… 除了…</p>
</li>
<li><p>we discuss each step in detail next and provide considerations on the probe below</p>
</li>
<li><p>we <strong>cover</strong> a variety of sources</p>
</li>
<li><p><strong>to what extent</strong> aligned texts （对应的文本）exist 在某种程度上</p>
</li>
<li><p>one can expect that …, and this is indeed the case:</p>
</li>
<li><p>with respect to 关于…</p>
</li>
<li><p>…will become a viable alternative to …将会成为一个可行的替代方案</p>
</li>
<li><p>recent work has presented <strong>intriguing</strong> results</p>
</li>
<li><p>these prompts are usually manually created, and quite possibly suboptimal</p>
</li>
<li><p>Because of this, given an inappropriate prompt, wemight <strong>fail to retrieve facts that the LM does know,</strong> and thus any given prompt only <strong>provides a lower bound estimate of</strong> the knowledge contained in an LM.</p>
</li>
<li><p>achieve a number of intriguing results <strong>regarding</strong> the knowledge</p>
</li>
<li><p>Thus it is quite possible that a fact that the LMdoes know cannot be retrieved due to the prompts not being effective queries for the fact.</p>
</li>
<li><p>写法可以借鉴：<strong>In this paper we ask the question:</strong> “How can we <strong>tighten this lower bound and get a more accurate estimate of the knowledge contained in state-of-the-art LMs</strong>?” <strong>This is interesting both scientifically,</strong> as a probe of the knowledge that LMs contain, <strong>and from an engineering perspective</strong>, as it will result in higher recall when using LMs as part of a knowledge extraction system.</p>
</li>
<li><p>an English-language benchmark <strong>devised to</strong> test the ability 被设计用来…</p>
</li>
<li><p>We perform extensive analysis and ablations, <strong>gleaning insights</strong> both about how to best query the knowledge stored in LMs and about potential directions for incorpo- rating knowledge into LMs themselves 收集了关于…的想法（洞察力）</p>
</li>
<li><p>to facilitate future experiments  以方便今后的实验 </p>
</li>
<li><p>a “good” prompt should <strong>trigger the LM to predict</strong> the ground- truth objects as often as possible</p>
</li>
<li><p>we <strong>tackle</strong> prompt generation: 也可以这样给出定义，用这个词</p>
</li>
<li><p>then <strong>uses the phrase spanning from</strong> the left- most word <strong>to</strong> the rightmost word in the dependency path as a prompt. spanning from从…到…</p>
</li>
<li><p><strong>be prone to noise</strong> 容易产生噪声</p>
</li>
<li><p>we <strong>assess the extent to which our prompts can improve fact prediction performance</strong>, raising the lower bound on the knowledge we dis-cern is contained in LMs.</p>
</li>
<li><p>to mitigate this problem 为了缓和这种问题&#x2F;解决</p>
</li>
<li><p>we also <strong>depict</strong> the performance of…  描述&#x2F;描绘</p>
</li>
<li><p>prompts will <strong>yield</strong> different predictions 产生不同结果用这个词</p>
</li>
<li><p><strong>it is of interest to know whether</strong> … or whether they can …</p>
</li>
<li><p>recent years have featured a trend towards…</p>
</li>
<li><p>many <strong>exaggerate</strong> actual performance on the <strong>underlying task</strong> 夸大了实际的底层任务的性能</p>
</li>
<li><p>aside from pointing to a conceptual limitation in our current NLP techniques 除了指出当前NLP技术的概念局限性之外</p>
</li>
<li><p>to be broadly useful, we would someday ….</p>
</li>
<li><p><strong>one potential route</strong> towards <strong>addressing these issues</strong> is …</p>
</li>
<li><p>results far inferior to 结果远不如</p>
</li>
<li><p><strong>Another recent trend in language modeling may offer a way forward</strong>. In recent years the capacity of transformer language models <strong>has increased substantially,</strong> from 100 million parameters, to 300 million parameters , to 1.5 billion parameters, to 8 billion parameters, 11 billion parameters, and finally 17 billion parameters.  描写transformer的语言模型最近规模的增长的</p>
</li>
<li><p>the results in this case are particularly <strong>striking</strong> 结果十分出色，引人注目</p>
</li>
<li><p>achieve <strong>promising</strong> results in the zero-shot and one-shot settings 达到了十分有前途的结果</p>
</li>
<li><p>the few-shot setting <strong>is sometimes competitive with or even occasionally surpasses state-of-the-art</strong>     few-shot的设置有时可以与最先进的技术竞争，甚至偶尔会超过。</p>
</li>
<li><p><strong>A heuristic sense of</strong> the overall results can be seen in Figure，which <strong>aggregates the various tasks</strong> 对整体结果的启发式认识可以从图中看出，该图汇总了各种任务</p>
</li>
<li><p>we also <strong>undertake a systematic study</strong> of… 我们还对…进行了系统的研究</p>
</li>
<li><p>Finally, given the broad spectrum of capabilities dispalyed by… 鉴于GPT-3所展示的广泛能力</p>
</li>
<li><p>attempt a preliminary analysis of … 尝试对…进行初步分析。</p>
</li>
<li><p>dataset <strong>constituting</strong> nearly a trillion words 由…组成</p>
</li>
<li><p>Large language models have recently been shown to <strong>attain reasonable zero-shot generalization</strong> on a diverse set of tasks</p>
</li>
<li><p>It has been <strong>hypothesized</strong> that …</p>
</li>
<li><p>to test this question <strong>at scale</strong> …</p>
</li>
<li><p>Recent work has shown that large language models <strong>exhibit the ability</strong> to perform reasonable zero- shot generalization to new tasks  大型语言模型展现出…样的能力</p>
</li>
<li><p>在写多语言论文的introduction的时候可以这样借鉴：</p>
<p>In this paper, we <strong>focus on explicitly training language models in a supervised and massively multi- task fashion</strong>. <strong>Our approach uses</strong> a training mixture consisting of a large set of different tasks speci-fied in natural language prompts. <strong>Our goal is to</strong> induce a model to better generalize to held-out tasks without requiring massive scale, as well as being more robust to the wording choices of the prompts. To convert a large set of natural language tasks into prompted form, we use a simple templating language for structured datasets. <strong>We develop an interface for prompt collection</strong> from public contributors that facilitated the collection of a large multitask mixture with multiple prompts per dataset (Bach et al., 2022). <strong>We then train a variant of the T5 encoder-decoder model</strong> (Raffel et al., 2020; Lester et al., 2021) <strong>on a subset of the tasks</strong> (each with multiple datasets) and <strong>then evaluate tasks and prompts that the model was not trained on</strong>.</p>
<p><strong>Our experiments study two questions.</strong> First, does multitask prompted training improve generalization to held-out tasks? Second, does training on a wider range of prompts improve robustness to prompt wording? For the first question, <strong>we find that multitask training enables zero-shot task generalization by showing that our model matches or exceeds the performance of GPT-3 (Brown et al., 2020) on 9 out of 11 held-out datasets, despite being about 16× smaller.</strong> We also show that the model improves over a large baseline language model on 13 out of 14 tasks in the BIG-bench benchmark (BIG-bench collaboration, 2021). <strong>For the second question, we find that training on more prompts per dataset consistently improves the median and decreases the variability of performance on held-out tasks.</strong> Training on prompts from a wider range of datasets also generally improves the median but does not consistently decrease the variability.</p>
</li>
<li><p>However, <strong>the extent to which this success depends on</strong> the semantic meaningfulness of the prompts has been challenged (Webson and Pavlick, 2021; Logan et al., 2021). Thus, in this work, <strong>we remain agnostic as to why prompts support generalization.</strong> </p>
</li>
<li><p>to evaluate zero-shot generalization to new tasks 为了评估对于新任务的零样本泛化性能</p>
</li>
<li><p>we err on the side of … as opposed to 我们偏向于，而不是…</p>
</li>
</ol>
<h2 id="Word"><a href="#Word" class="headerlink" title="Word"></a>Word</h2><p>大模型的另一种表达：pretrained high-capacity language models</p>
<p>extract relational data from <strong>text or other modalities</strong>  从文本数据或者一些其它模态的数据</p>
<p><strong>populate</strong>：populate knowledge bases 填充数据库</p>
<p>off-the-shelf 现成的 in pretrained off-the-shelf language models</p>
<p>knowledge base completion literature</p>
<p>canonical ways 权威的</p>
<p>单词缩写：<strong>language models(LM)</strong> by having the <strong>LM</strong></p>
<p>prompt ensemble prompt集成</p>
<p>substantially 大量的</p>
<p>deterministic 确定性的查询</p>
<p><strong>retrive&#x2F;elicite</strong> knowledge from the LM 从语言模型里获取知识</p>
<p>be affiliated with the religion 有着…的信仰</p>
<p><strong>concatenate</strong> them with… 把…拼接起来</p>
<p><strong>be conducive to</strong>…有助于</p>
<p>one-shot and few-shot <strong>proficiency</strong>  one-shot和few-shot的熟练程度</p>
<p><strong>unscrambling</strong> words解密单词</p>
<p>performe arithmetic 执行算术</p>
<p><strong>inflating</strong> results 一些夸大的结果</p>
<p>data <strong>contamination</strong> 数据污染</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/Paper-Writing/">#Paper Writing</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>英文论文写作表达积累</div>
      <div>http://example.com/2022/07/13/英文论文写作表达积累/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>John Doe</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2022年7月13日</div>
        </div>
      
      
      <div class="license-meta-item">
        <div>许可协议</div>
        <div>
          
            
            
              <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
              <span class="hint--top hint--rounded" aria-label="BY - 署名">
                <i class="iconfont icon-by"></i>
              </span>
              </a>
            
          
        </div>
      </div>
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2022/07/13/%E3%80%8ALanguage-Models-as-Knowledge-Bases-%E3%80%8B%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" title="《Language Models as Knowledge Bases?》论文阅读笔记">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">《Language Models as Knowledge Bases?》论文阅读笔记</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2022/07/11/%E7%A0%94%E7%A9%B6%E6%96%B9%E5%90%91%E4%B9%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%8F%8A%E6%9C%8D%E5%8A%A1-LMaaS/" title="研究方向之语言模型及服务(LMaaS)">
                        <span class="hidden-mobile">研究方向之语言模型及服务(LMaaS)</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      headingSelector : CONFIG.toc.headingSelector || 'h1,h2,h3,h4,h5,h6',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      collapseDepth   : CONFIG.toc.collapseDepth || 0,
      scrollSmooth    : true,
      headingsOffset  : -boardTop
    });
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
