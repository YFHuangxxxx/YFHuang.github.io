

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="John Doe">
  <meta name="keywords" content="">
  
    <meta name="description" content="paper： https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1911.12543 code： GitHub - jzbjyb&#x2F;LPAQA: Language model Prompt And Query Archive    Abstract最近的工作提出了耐人寻味的结果，通过让语言模型（LM）填写 “Obama is a by profession”这样的提示信息，来研究语言模型（LM）">
<meta property="og:type" content="article">
<meta property="og:title" content="《How Can We Know What Language Models Know?》论文阅读笔记">
<meta property="og:url" content="http://example.com/2022/07/14/%E3%80%8AHow-Can-We-Know-What-Language-Models-Know-%E3%80%8B%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="paper： https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1911.12543 code： GitHub - jzbjyb&#x2F;LPAQA: Language model Prompt And Query Archive    Abstract最近的工作提出了耐人寻味的结果，通过让语言模型（LM）填写 “Obama is a by profession”这样的提示信息，来研究语言模型（LM）">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://img-blog.csdnimg.cn/0a9ec5ea0a51434fb3c7bce9a3d3f9a0.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/83dee73ae6c04900867b8c50b57ea199.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5YyX5Zyo5ZOq,size_20,color_FFFFFF,t_70,g_se,x_16">
<meta property="og:image" content="https://img-blog.csdnimg.cn/535b998eec834db69f6d55f083240db6.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/96f2c661b26e495ca948d77b9048f082.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/056a360380614669b92d7d8d7c7bdc4c.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/c5d16dd0d8814ff0a38229956fba94dc.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/8fde89fb1abf4780a4a447d01837c6be.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/070251def5334d3dbd41dccad0f26eb9.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/87bb968051f04492bec9ff3d1f94643e.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/6600edd7bf0041c796595bbcd22ec921.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/62f40ebe8c1547239e0b2149585b0d26.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/846350ee7c1444bdb915056c975e0c2a.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/92a39f54f9c14c708a791e6a4c6c0218.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/234f002631b447d494ddc0bf50ce4977.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/cf53960052554e0286563522f28ce1ca.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/005abb5350c34c27a4d96eb49490fead.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/eed43790e1c4443fbf18b1e6de3a5420.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/bd6703c4935c45cd90cf95f0013e0ed4.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/8f50381e24454a7a92d2d97656b72d26.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/d069eb0cfdf347aa97510234a84b9ab9.png">
<meta property="article:published_time" content="2022-07-14T02:57:57.000Z">
<meta property="article:modified_time" content="2022-07-25T08:27:03.435Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="Paper Reading">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://img-blog.csdnimg.cn/0a9ec5ea0a51434fb3c7bce9a3d3f9a0.png">
  
  
  
  <title>《How Can We Know What Language Models Know?》论文阅读笔记 - Hexo</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.2","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":"1m3N9eCbJotF9LhDStTghTjW-gzGzoHsz","app_key":"EVUJOCDpAEdmSIvo1hzRA9Gd","server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  

  

  

  

  

  

  
    
  



  
<meta name="generator" content="Hexo 6.2.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>YFHuang&#39;s blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/test.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="《How Can We Know What Language Models Know?》论文阅读笔记"></span>
          
        </div>

        
          
  <div class="mt-3">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-author" aria-hidden="true"></i>
        John Doe
      </span>
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2022-07-14 10:57" pubdate>
          2022年7月14日 上午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          6.7k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          56 分钟
        
      </span>
    

    
    
      
        <span id="leancloud-page-views-container" class="post-meta" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="leancloud-page-views"></span> 次
        </span>
        
      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">《How Can We Know What Language Models Know?》论文阅读笔记</h1>
            
            
              <div class="markdown-body">
                
                <p>paper： <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1911.12543">https://arxiv.org/abs/1911.12543</a></p>
<p>code： <a target="_blank" rel="noopener" href="https://github.com/jzbjyb/LPAQA">GitHub - jzbjyb&#x2F;LPAQA: Language model Prompt And Query Archive</a>  </p>
<p><img src="https://img-blog.csdnimg.cn/0a9ec5ea0a51434fb3c7bce9a3d3f9a0.png" srcset="/img/loading.gif" lazyload alt="在这里插入图片描述"></p>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>最近的工作提出了耐人寻味的结果，通过让语言模型（LM）填写 “Obama is a by profession”这样的提示信息，来研究语言模型（LM）中包含的知识。这些提示通常是人工创建的，而且很可能是次优的；另一个提示如 “Obama worked as a”可能会导致更准确地预测正确的职业。正因为如此，给定一个不恰当的提示，我们可能无法检索到语言模型确实知道的事实，因此任何给定的提示只能提供语言模型所含知识的下限估计。在本文中，我们试图通过自动发现更好的提示来更准确地估计LM中所包含的知识，以便在这个查询过程中使用。具体来说。论文<strong>提出了基于挖掘（mining-based）和基于释义（paraphrasing-based）的方法来自动生成高质量和多样化的提示，以及集成方法来组合来自不同提示的答案</strong>，用以更准确地估计 LM 中包含的知识，主要使用的数据集是LAMA。</p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>近年来，语言模型（LM）的主要作用从<strong>生成或评估自然文本的流畅性</strong>过渡到<strong>成为文本理解的有力工具</strong>。这种理解主要是通过使用语言修改作为特征提取器的预训练任务来实现的。其中，通过语言建模目标学到的隐藏向量随后被用于下游语言理解系统。有趣的是，现在也越来越明显地发现 <strong>LM本身可以作为文本理解的工具</strong>，通过用自然语言制定查询，并直接生成文本答案，或者评估多个选择并挑选出最有可能的一个。例如，LM被用来回答事实性问题，回答常识性查询，或提取关于实体之间关系的事实性知识。无论最终的任务是什么，LM中包含的知识都是通过提供提示，让LM生成前缀的延续（例如 “巴拉克-奥巴马出生于”），或者预测cloze-style模板中的缺失单词（例如 “巴拉克-奥巴马是一个职业”）来探究。</p>
<p>然而，虽然这种范式已经被用来实现一些关于LMs所表达的知识的有趣的结果，但它们通常依赖于基于实验者的直觉而手工创建的提示语。<strong>这些手动创建的提示（如 “巴拉克-奥巴马出生在”）可能是次优的</strong>，因为中枢神经系统可能已经在他们的训练中从大大不同的语境（如 “巴拉克-奥巴马的出生地是夏威夷的檀香山”）中学习了目标知识。因此，很有可能由于提示不是对事实的有效查询，LM所知道的事实不能被检索出来。因此，现有的结果只是对LM所包含的知识程度的一个下限，事实上，LM的知识可能比这些初步结果所显示的还要丰富。<strong>在本文中，我们提出了一个问题。”我们如何才能收紧这个下限，并对最先进的LM所包含的知识有一个更准确的估计？”</strong> 这在科学上是很有趣的，因为它是对LM所包含的知识的探测，从工程的角度来看，当使用LM作为知识提取系统的一部分时，它将导致更高的召回率。</p>
<p>特别是，我们专注于Petroni等人（2019）的设定（LAMA），他们研究提取有关实体之间关系的知识。我们提出了两种自动方法来系统地改善用于查询关系存在的提示的广度和质量。<strong>这些方法是基于挖掘的方法</strong>，其灵感来自以前的关系提取方法，<strong>以及基于转述的方法，该方法采用一个种子提示（无论是手动创建的还是自动挖掘的）</strong>，<strong>并将其转述为其他几个语义相似的表达</strong>。此外，由于在查询不同的主客体对时，不同的提示语可能效果更好，<strong>我们还研究了轻量级的集合方法，将不同提示语的答案组合在一起</strong>。</p>
<p>我们在LAMA基准上进行了实验，这是一个英语基准，用来测试LM检索实体之间关系的能力。我们首先证明，改进后的提示明显提高了这项任务的准确性，我们的方法提取的最佳提示在BERT-base上将准确性从31.1%提高到34.1%，在BERT-large上也获得了类似的收益。我们进一步证明，通过合奏使用多样化的提示，进一步提高了准确性，达到39.6%。我们进行了广泛的分析和消减，<strong>既收集了关于如何最好地查询存储在LM中的知识的见解，也收集了关于将知识纳入LM本身的潜在方向的见解</strong>。最后，我们发布了由此产生的LM提示和查询档案（LPAQA），以促进未来对LM中包含的知识进行探测的实验。</p>
<h2 id="Prompt-Generation"><a href="#Prompt-Generation" class="headerlink" title="Prompt Generation"></a>Prompt Generation</h2><p>论文为每种实体关系考虑了两种提示模板生成方法：基于挖掘的方法和基于释义的方法。</p>
<p>1）<strong>基于挖掘的方法</strong></p>
<p>​    首先使用远程监督，从维基百科中提取出包含LAMA数据集主客体并描述了它们之间的关系的句子。</p>
<p><strong>Middle-word Prompts</strong> 以往的研究表明，主客中间的词往往表示关系，因此可以直接用这些词作为提示，例如，通过用占位符替换主语和宾语，“Barack Obama was born in Hawaii” 可以被转换为提示：“x was born in y”。</p>
<p><strong>Dependency-based Prompts</strong> 论文还指出，主客体之间没有出现文字时（比如“The capital of France is Paris”），可以使用依存解析器解析句子，找出主客间最短依存路径作为提示，比如上述例子的最短依存路径如下图所示， 可以转换为提示：“capital of x is y”。</p>
<p><img src="https://img-blog.csdnimg.cn/83dee73ae6c04900867b8c50b57ea199.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5YyX5Zyo5ZOq,size_20,color_FFFFFF,t_70,g_se,x_16" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>2）<strong>基于释义的方法</strong></p>
<p>​    将原有的提示改为其他语义相似或相同的表达来实现，比如说，如果原始提示是“x shares a border with y”，那可以改写为“x has a common border with y”和“x adjoins y”。这在概念上类似于信息检索中使用的查询扩展技术，后者重新制定给定的查询以提高检索性能。</p>
<p>​    <strong>论文使用回译的方法来实现释义</strong>，即先将原始提示翻译成其他语言的个候选，然后对于每一个候选再将其翻译回英语，这样就可以得到个提示，最后根据round-trip概率（如下）进行排序选最优的top T个。</p>
<p><img src="https://img-blog.csdnimg.cn/535b998eec834db69f6d55f083240db6.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<h2 id="Prompt-Selection-and-Ensembling"><a href="#Prompt-Selection-and-Ensembling" class="headerlink" title="Prompt Selection and Ensembling"></a>Prompt Selection and Ensembling</h2><p>1）Top-1 Prompt Selection</p>
<p>  对于每一种关系，分别使用候选提示对训练集预测，只选择使得训练集准确率最高的一个提示作为最终提示。</p>
<p>2）Rank-based Ensemble</p>
<p>​    首先，对于每一种关系，根据训练集准确率对候选提示进行排序，选择前个提示与输入拼接进行预测，简单将所有提示的输出概率取平均，作为最终输出概率，然后再softmax。</p>
<p><img src="https://img-blog.csdnimg.cn/96f2c661b26e495ca948d77b9048f082.png" srcset="/img/loading.gif" lazyload alt="在这里插入图片描述"></p>
<p>3）Optimized Ensemble</p>
<p>​    前面所有的方法都是将top K个prompts平等对待，直接进行加权平均，在第三种方法中引入了学习权重，对于每一种关系，引入可学习权重，最终输出概率为top 个提示输出概率的加权和。</p>
<p><img src="https://img-blog.csdnimg.cn/056a360380614669b92d7d8d7c7bdc4c.png" srcset="/img/loading.gif" lazyload alt="在这里插入图片描述"></p>
<h2 id="Main-Experiment"><a href="#Main-Experiment" class="headerlink" title="Main Experiment"></a>Main Experiment</h2><h3 id="实验设置"><a href="#实验设置" class="headerlink" title="实验设置"></a>实验设置</h3><p><strong>Dataset：</strong>T-REx subset of LAMA；T-REx-UHN；T-REx-train</p>
<p><img src="https://img-blog.csdnimg.cn/c5d16dd0d8814ff0a38229956fba94dc.png" srcset="/img/loading.gif" lazyload alt="在这里插入图片描述"></p>
<p><strong>Model：</strong>BERT-base；BERT-large；ERNIE；KnowBert</p>
<p><strong>Evaluation Metrics：</strong>micro-averaged accuraccy；macro-averaged accuracy</p>
<p><strong>Methods：</strong>Mine+Man vs Mine+Para vs Man+Para</p>
<h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p>所有的实验结果都是围绕以下两张表的结果展开的：</p>
<p><img src="https://img-blog.csdnimg.cn/8fde89fb1abf4780a4a447d01837c6be.png" srcset="/img/loading.gif" lazyload alt="在这里插入图片描述"></p>
<p><img src="https://img-blog.csdnimg.cn/070251def5334d3dbd41dccad0f26eb9.png" srcset="/img/loading.gif" lazyload alt="在这里插入图片描述"></p>
<p>将基于挖掘的方法生成的提示与手动设计的提示使用可学习权重进行集成，在BERT-base和BERT-large上都取得了最优结果。</p>
<h4 id="1-Single-Prompt-Experiment"><a href="#1-Single-Prompt-Experiment" class="headerlink" title="1) Single Prompt Experiment"></a>1) Single Prompt Experiment</h4><p>当只使用一个提示时（在两个表中的Top1列中），所提出的提示生成方法中最好的方法在BERT-base上将微观平均准确率从31.1%提高到34.1%，在BERT-large上从32.3%提高到39.4%。这表明手动创建的提示是一个有点弱的下限；还有其他提示可以进一步提高从LM查询知识的能力。<br>表4显示了一些挖掘出来的提示语，与人工提示语相比，这些提示语带来了很大的性能提升。</p>
<p><img src="https://img-blog.csdnimg.cn/87bb968051f04492bec9ff3d1f94643e.png" srcset="/img/loading.gif" lazyload alt="在这里插入图片描述"></p>
<p>对于宗教关系，”x who converted to y”比人工定义的提示 “x is affiliated with the y religion”提高了60.0%；对于关系subclass_of，”x is a type of y”比 “x is a subclass of y”提高了22.7%的准确性。可以看出，<strong>使用挖掘出来的提示语的最大收益似乎发生在人工定义的提示语在句法上更复杂的情况下（例如前者），或者使用比挖掘出来的提示语更不常见的措辞时（例如后者）。</strong></p>
<h4 id="2-Prompt-Ensembling（Prompt集成）"><a href="#2-Prompt-Ensembling（Prompt集成）" class="headerlink" title="2) Prompt Ensembling（Prompt集成）"></a>2) Prompt Ensembling（Prompt集成）</h4><p>然后将第1栏中的单一提示结果与下面三栏中的组合结果进行比较，我们可以看到，组合多个提示几乎总是能带来更好的性能。在不同的提示生成方法中，<strong>Top3和Top5中使用的简单平均值优于Top1</strong>。优化后的合集在BERT-base和BERT-large上进一步将微观平均准确率分别提高到38.9%和43.7%，比基于等级的合集要好得多。这两组结果表明，<strong>不同的提示可以以不同的方式查询LM，而基于优化的方法能够找到有效地将不同提示结合在一起的权重</strong>。</p>
<p>我们在表5中列出了所学到的前3名提示的权重，以及与只使用前1名提示相比的准确度提升。</p>
<p><img src="https://img-blog.csdnimg.cn/6600edd7bf0041c796595bbcd22ec921.png" srcset="/img/loading.gif" lazyload alt="在这里插入图片描述"></p>
<p>权重倾向于集中在一个特定的提示上，而其他提示则作为补充。我们还在图2中描述了基于等级的合集方法的表现，与提示的数量有关。</p>
<p><img src="https://img-blog.csdnimg.cn/62f40ebe8c1547239e0b2149585b0d26.png" srcset="/img/loading.gif" lazyload alt="在这里插入图片描述"></p>
<p>对于挖掘出来的提示语，前2名或前3名通常会给我们最好的结果，而对于转述的提示语，前5名是最好的。<strong>纳入更多的提示语并不总是能提高准确性，这一发现与基于优化的方法所学到的权重迅速下降相一致。</strong>Oracle和Opti.之间的差距表明，使用更好的集合方法仍有改进空间。</p>
<h4 id="3-Mining-vs-Paraphrasing"><a href="#3-Mining-vs-Paraphrasing" class="headerlink" title="3) Mining vs. Paraphrasing"></a>3) Mining vs. Paraphrasing</h4><p>对于rank-based的合集（Top1, 3, 5），通过转述产生的prompt通常比挖掘的提示语表现得更好，而对于基于优化的合集（Opti.），挖掘的提示语表现得更好。我们推测这是因为与意译相比，挖掘出来的提示语表现出更多的变化，而适当的加权是至关重要的。这种变化的差异可以从每一类提示语之间的平均编辑距离中观察到，挖掘的提示语和意译的提示语的编辑距离分别为3.27和2.73。然而，与仅仅使用一个提示语相比，集合释义所带来的改进仍然是显著的（Top1 vs. Opti.），在BERT-base上的微观平均准确率从32.7%提高到36.2%，在BERT- large上从37.8%提高到40.1%。<strong>这表明，即使对prompt进行小的修改，也会导致预测的相对较大的变化。</strong></p>
<p><img src="https://img-blog.csdnimg.cn/846350ee7c1444bdb915056c975e0c2a.png" srcset="/img/loading.gif" lazyload alt="在这里插入图片描述"></p>
<p>表6显示了修改一个词（无论是功能词还是内容词）就能显著提高准确率的情况，表明大规模的LM对查询方式的微小变化仍有一定的影响。</p>
<h4 id="4-Middle-word-vs-Dependency-based"><a href="#4-Middle-word-vs-Dependency-based" class="headerlink" title="4) Middle-word vs. Dependency-based"></a>4) Middle-word vs. Dependency-based</h4><p><img src="https://img-blog.csdnimg.cn/92a39f54f9c14c708a791e6a4c6c0218.png" srcset="/img/loading.gif" lazyload alt="在这里插入图片描述"></p>
<p>作者在表7中比较了仅使用中间词提示和将其与基于依赖关系的提示相连接的性能。这些改进证实了我们的直觉，即<strong>属于依存关系路径但不在主语和宾语中间的词也是关系的指示</strong>。</p>
<h4 id="5-Micro-vs-Macro"><a href="#5-Micro-vs-Macro" class="headerlink" title="5) Micro vs. Macro"></a>5) Micro vs. Macro</h4><p>对比表2和表3，我们可以看到，macro-averaged accuracy 比micro-averaged accuracy低得多，这表明<strong>macro-averaged accuracy是一个更具挑战性的指标</strong>，它评估了LM知道多少独特的对象。我们基于优化的方法在BERT基础上将macro-averaged accuracy从22.8%提高到25.7%，在BERT基础上从25.7%提高到30.1%。这再次证实了集合多个提示的有效性，但收益稍小。值得注意的是，在我们基于优化的方法中，合集权重是在训练集的每个例子上进行优化的，这更有利于优化micro-averaged accuracy。优化以提高macro-averaged accuracy是未来工作的一个有趣的方向，可能会导致提示更普遍地适用于不同类型的obeject。</p>
<h4 id="6-Performance-of-Different-LMs"><a href="#6-Performance-of-Different-LMs" class="headerlink" title="6) Performance of Different LMs"></a>6) Performance of Different LMs</h4><p><img src="https://img-blog.csdnimg.cn/234f002631b447d494ddc0bf50ce4977.png" srcset="/img/loading.gif" lazyload alt="在这里插入图片描述"></p>
<p>在表8中，作者还将不同的模型：BERT与ERNIE和KnowBert进行了比较，后者通过更加明确地纳入实体嵌入来增强外部知识。ERNIE即使在手动定义提示的情况下也比BERT高出1分，但我们的提示生成方法进一步强调了两种方法之间的差异，使用Mine+Man方法的最高准确率数字相差了4.2分。<strong>这表明，如果对LM进行有效查询，高性能模型之间的差异可能会变得更加明显。</strong>KnowBert在LAMA上的表现不如BERT，这与Peters等人（2019）的观察相反。这可能是因为在Peters等人（2019）中，KnowBert被用来评估多标记主体&#x2F;对象，而LAMA只包含单标记对象。</p>
<h4 id="7-LAMA-UHN-Evaluation"><a href="#7-LAMA-UHN-Evaluation" class="headerlink" title="7) LAMA-UHN Evaluation"></a>7) LAMA-UHN Evaluation</h4><p><img src="https://img-blog.csdnimg.cn/cf53960052554e0286563522f28ce1ca.png" srcset="/img/loading.gif" lazyload alt="在这里插入图片描述"></p>
<p>表9报告了在LAMA-UHN基准上的表现。尽管与原始LAMA基准测试（表2）的表现相比，总体表现急剧下降，但优化后的组合仍能在很大程度上胜过人工提示，<strong>表明我们的方法在检索不能根据表面形式推断的知识方面是有效的</strong>。</p>
<h4 id="8-Performance-on-Google-RE"><a href="#8-Performance-on-Google-RE" class="headerlink" title="8) Performance on Google-RE"></a>8) Performance on Google-RE</h4><p><img src="https://img-blog.csdnimg.cn/005abb5350c34c27a4d96eb49490fead.png" srcset="/img/loading.gif" lazyload alt="在这里插入图片描述"></p>
<p>作者还在表10中报告了优化后的组合在Google- RE子集上的表现。同样，合集的多样化的提示提高了BERT-base和BERT-large模型的准确性。与T-REx子集相比，收益略小，这可能是由于只有3个关系，其中一个关系（预测一个人的出生日期）特别难，以至于只有一个提示产生非零的准确性。</p>
<h3 id="实验分析"><a href="#实验分析" class="headerlink" title="实验分析"></a>实验分析</h3><h4 id="1）不同提示的预测一致性分析"><a href="#1）不同提示的预测一致性分析" class="headerlink" title="1）不同提示的预测一致性分析"></a>1）不同提示的预测一致性分析</h4><p>使用以下公式计算同一关系下，不同提示产生的预测之间的发散度：</p>
<p><img src="https://img-blog.csdnimg.cn/eed43790e1c4443fbf18b1e6de3a5420.png" srcset="/img/loading.gif" lazyload alt="在这里插入图片描述"></p>
<p>若提示能够引导模型预测出正确结果，则，否则为0。以两个提示之间的编辑距离为横轴，预测发散度为纵轴，绘制箱型图如下：</p>
<p><img src="https://img-blog.csdnimg.cn/bd6703c4935c45cd90cf95f0013e0ed4.png" srcset="/img/loading.gif" lazyload alt="在这里插入图片描述"></p>
<p>随着编辑距离变大，发散度增加，这证实了我们的直觉，<strong>即非常不同的提示往往会导致不同的预测结果</strong>。Pearson 相关系数为 0.25，说明这两个量之间存在弱相关。</p>
<h4 id="2）基于词性的提示有效性分析"><a href="#2）基于词性的提示有效性分析" class="headerlink" title="2）基于词性的提示有效性分析"></a>2）基于词性的提示有效性分析</h4><p>符合以下三种句法规则的提示比其他提示的平均排名要高：</p>
<p><img src="https://img-blog.csdnimg.cn/8f50381e24454a7a92d2d97656b72d26.png" srcset="/img/loading.gif" lazyload alt="在这里插入图片描述"></p>
<p>我觉得这个实验分析的结果对之后的工作还是非常有启发性的，对于后续更多想要开发不同pattern的prompt具有很大的借鉴意义。</p>
<h4 id="3）跨模型一致性"><a href="#3）跨模型一致性" class="headerlink" title="3）跨模型一致性"></a>3）跨模型一致性</h4><p>最后，我们有兴趣知道，我们所提取的提示是否是针对某一特定模型的，或者<strong>它们是否可以在不同的模型中通用</strong>。为此，我们使用了两种设置：一种是比较BERT-base和BERT-large，即具有不同规模的相同模型架构；另一种是比较BERT-base和ERNIE，即具有相同规模的不同模型架构。在每一种情况下，我们都会比较基于优化的合集是<strong>在同一模型上训练，并在另一个模型上进行测试</strong>。如表12和表13所示，我们发现，一般来说，在跨模型的情况下，性能通常会有一些下降（第三和第五列），但损失往往很小，在查询BERT-base时，最高的性能实际上是由在BERT-large上优化的权重实现的。值得注意的是，在另一个模型上优化的权重的最佳准确率为40.1%和42.2%（表12）和39.5%和40.5%（表13），仍然比手动提示获得的准确率高得多，这表明优化的提示仍然能在不同的模型上提供大的收益。另一个有趣的观察是，<strong>在ERNIE上的性能下降（表13的最后两列）比在BERT-base上使用优化权重的BERT-large（表12的最后两列）要大，表明共享相同结构的模型从相同的提示中受益更多</strong>。</p>
<h4 id="4）线性与对数线性的结合"><a href="#4）线性与对数线性的结合" class="headerlink" title="4）线性与对数线性的结合"></a>4）线性与对数线性的结合</h4><p><img src="https://img-blog.csdnimg.cn/d069eb0cfdf347aa97510234a84b9ab9.png" srcset="/img/loading.gif" lazyload alt="在这里插入图片描述"></p>
<p>我们从上图可以看到，对数线性组合胜过线性组合，因为对数概率使我们有可能惩罚那些在任何特定提示下都是非常不可能的对象。</p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>在这篇文章中，作者研究了用于从语言模型中检索事实知识的提示语的重要性。<strong>作者提出了mining-based和paraphrasing-based的方法</strong>，以系统地生成不同的提示语来查询特定的关系知识片段。<strong>这些提示语结合在一起时，将事实知识的检索准确率提高了8%，比人工设计的提示语要好得多</strong>。我们的分析表明，LMs确实比以前的结果所显示的更有知识，但它们对我们如何查询它们也相当敏感。<strong>这表明了未来的潜在方向，例如：（1）可以用不同的方式查询但仍然返回类似的结果的更强大的LM，（2）LM中的事实知识的方法，以及（3）在优化LM的知识查询方法方面的进一步改进。</strong></p>
<h2 id="My-idea"><a href="#My-idea" class="headerlink" title="My idea"></a>My idea</h2><p>这篇文章对我比较有启发意义的是其实它的最主要的实验做得比较简单，但是实验结果的多维度分析以及关于很多因素的讨论是我十分需要学习的，在上一次写paper去完善自己的实验的时候，很多时候是不知道应该去做一些什么样的实验的，这里首先给了我一个想法：<strong>在写指令式的prompt的时候可以通过实验找到最适合不同的下游任务的句式，多样化的指令式的prompt也可以引入学习权重，而不是简单的进行集合。</strong></p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/Paper-Reading/">#Paper Reading</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>《How Can We Know What Language Models Know?》论文阅读笔记</div>
      <div>http://example.com/2022/07/14/《How-Can-We-Know-What-Language-Models-Know-》论文阅读笔记/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>John Doe</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2022年7月14日</div>
        </div>
      
      
      <div class="license-meta-item">
        <div>许可协议</div>
        <div>
          
            
            
              <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
              <span class="hint--top hint--rounded" aria-label="BY - 署名">
                <i class="iconfont icon-by"></i>
              </span>
              </a>
            
          
        </div>
      </div>
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2022/07/15/%E8%AE%BA%E6%96%87%E9%9B%86%E6%80%9D/" title="论文集思">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">论文集思</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2022/07/13/%E3%80%8ALanguage-Models-as-Knowledge-Bases-%E3%80%8B%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" title="《Language Models as Knowledge Bases?》论文阅读笔记">
                        <span class="hidden-mobile">《Language Models as Knowledge Bases?》论文阅读笔记</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      headingSelector : CONFIG.toc.headingSelector || 'h1,h2,h3,h4,h5,h6',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      collapseDepth   : CONFIG.toc.collapseDepth || 0,
      scrollSmooth    : true,
      headingsOffset  : -boardTop
    });
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script defer src="/js/leancloud.js" ></script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
